[Getting Pixels onto the Screen](https://www.objc.io/issues/3-views/moving-pixels-onto-the-screen/)



​	一个像素是如何绘制到屏幕上的呢？有很多方法可以将某些东西绘制到显示器上，他们涉及到很多不同的框架以及函数与方法的结合体。这里我们可以探究一些在屏幕后面发生的事情。我们希望这可以帮助你理解，当你需要决定什么时候并且怎么样去调试喝修复性能问题的时候，哪个API可以最好的去工作。我们将会专注讨论iOS，当然，大部分的讨论结果，同样适用于OS X。

### 图形栈

当像素绘制到屏幕上时，后台其实做了非常多的事情。一旦他们被渲染到屏幕上时，每个像素都是由红，绿，蓝三种颜色构成的。三个被特定强度点亮的颜色单元，给我们的印象就是一个特定颜色的像素（其实就是三个颜色单元 + alpha = 像素）。在你的iPhone5上，液晶屏有1136 * 640 = 727070个像素，因此有2181120个颜色单元。在15寸带视网膜屏幕的的MacBook Pro中，就拥有15.5亿个像素。整个图形栈协同工作以确保图形被正确的显示。当你全屏滑动时，数以百万计的像素必须以每秒60次的频率刷新。这是一个很大的工作量。

### 软件组成

从一个简单的角度看，一个软件的堆栈就像下面这样：

![](https://www.objc.io/images/issue-3/pixels-software-stack@2x_1ae69f5.png)

在显示器的上一层就是GPU，即图形处理单元。GPU是一个高效的并发处理单元，并且他是为图形的并行计算而特别量身定制的。这也是为什么它能够更新所有的像素，并且将结果绘制到屏幕上去。它并行的特性也就允许它能高效的将不同的纹理合并成一个。我们将会说更多与合成细节相关的东西。关键点就是，GPU是如此的特俗，因此它可以非常高效的做一些特定的工作。相比于CPU来说，GPU会花费更少的时间，更快的速度去完成这些工作。普通的CPU有一个常用的目的：它可以处理很多不同的事物，但是对于合成图像，它会执行的非常慢。

GPU的驱动是一系列直接与GPU交互的代码。不同的GPU是不同的野兽，但是驱动使他们在下一层级显示的更为统一，这里的下一层级就是OpenGL/OpenGL ES。

OpenGL（Open Graphic Library）是一个为了渲染2D和3D图像的API。因为GPU是一块非常特殊的硬件，OpenGL与GPU工作非常紧密，以促进GPU的能力以及实现硬件加速的渲染。对于很多人来说，OpenGL可能看起来非常底层，但是当他第一次在1992年发布的时候，它是第一个主要与图形硬件交流的标准化的方法，这是一个重大的飞跃，因为程序员不需要再为每个GPU重写他们的App。

OpenGL的上一层被分为了几块。在iOS上，几乎所有的东西都是通过Core Animation绘制出来的，但是在OS X上，绕过Core Animation去用Core Graphic的情况并不少见。对于一些特殊的应用，特别是游戏，App可能会与OpenCL/OpenGL ES直接交流。然后事情变得越来越扑所迷离，因为在某些东西的渲染上，Core Animation会使用到Core Graphic。一些像AVFoundation，Core Image 以及其他一些混合入口的框架。

有一件事情我们必须要知道，GPU是一个非常强大的图形处理硬件，并且在展示像素的时候起着核心的作用。它连接到了CPU。从硬件上来说，它们之间存在着某种总线。这里有一些像OpenGL，Core Animation，以及Core Graphic的框架编排着GPU与CPU之间传递的数据。为了让你的像素展示到屏幕上，一些处理工作会在CPU上完成。然后数据会传输到GPU相对应的也会对数据做一些处理，然后最后你的像素就会显示到屏幕上。

这个过程中的每一部分都有自己的挑战，并且许多时候需要做出一些折中的选择。

### 硬件参与者

![](https://www.objc.io/images/issue-3/pixels%2C%20hardware%402x.png)

正如上面这张简单的图片所带来的挑战这样：GPU具有为每一帧（一秒钟60次）所合成的纹理（位图）。每个纹理都占用着VRAM（Virtual random access memory：虚拟随机访问内存）， 因此它也限制了GPU可以拥有的纹理数量。GPU在合成上是非常高效的，但是一些特定的合成任务会比其他的更加的复杂，并且GPU在16.7ms中能做的事情是有限的。

接下来的挑战就是把你的数据传递到GPU。为了能让GPU接收数据，它需要从RAM被传递到VRAM。这个过程可以看成是被上传到GPU。这可能看起来有点微不足道，但是对于很大的纹理来说是非常耗时的。

最后，CPU会运行你的程序。你可能会告诉CPU从bundle中加载一张PNG格式的图片，并且解码它。所有的这些都发生在CPU。当你想要展示这张解码的图片时，它就需要通过某种方式上传到GPU。像一些展示文本这种及其简单的事，对于CPU来说也是非常复杂的。这会促使Core Text与Core Graphics更加紧密的合作来生成一张文本的位图。一旦准备就绪，它会作为纹理被上传到GPU，然后准备被渲染到屏幕上去。当你滑动或者在屏幕上移动文本时，一些非常相似的纹理会被重用，并且CPU会简单的告诉GPU一些新的位置坐标，所以GPU可以重用已经存在的纹理。CPU不需要去重新渲染文本，位图也不需要被重新上传。

上述这些说明了所涉及到的复杂性。有个大概的了解之后，我们再深入了解所涉及到的技术。



### 合成

合成在图像世界中，是一个描述怎么把不同的位图合并到一起，最终形成一张图片展示到屏幕上的术语。这在很多情况下，显然会让我们很轻易的遗忘它所涉及到的计算的复杂性。

让我们先忽略掉一些深奥的例子，然后假设所有在屏幕上展示的都是纹理。纹理是一个存储着RGBA数据的矩形区域。每个像素都包含了红，绿，蓝以及透明度的值。在Core Animation中，这也是CALayer的基础组成部分。

在这个简化的设置中，每个layer都是一个纹理，所有的这些纹理都以某种方式堆叠在彼此的顶端。对于每个在屏幕上的像素来说，GPU需要算出如何混合这些纹理中的像素后的RGBA的值。这也是合成的意思。

如果所有我们拥有的都是一张屏幕大小的简易的纹理，并且与屏幕像素点对齐，每个在屏幕上的像素都会对应纹理中的像素。那么纹理的像素也就是屏幕的像素。

如果我们有另一张纹理被放置在了第一张纹理上，GPU就会需要在第一张纹理上去合成这张纹理。这里有不同的混合模式，但是如果我们假设两张纹理都是像素对齐的，我们也使用普通的混合方式，那么结果的颜色就可以根据下面这个公式获得：

``` R = S + D * (1 - Sa)
R = S + D * (1 - Sa)
```

结果的颜色就是源颜色（即在上面一层的纹理的像素值）加上目标颜色（第一层级的像素值）乘以 1 减去源颜色的透明度。所有在这个公式中的颜色，我们都假定已经预先乘了它们的透明度。

很显然这里会发生一些事情。让我们做第二个假设，那就是所有的纹理都是不透明的，即alpha=1。如果目标纹理是蓝色，源纹理是红色，因为源纹理的透明度是1，因此结果就是：

```
R = S
```

那么结果就是源纹理的红色。这也是你所期望看到的。

如果源色层是50%的透明度，即alpha=0.5，因为RGB的预先乘了Alpha的值，那么S的RGB的值就是（0.5， 0， 0）。那么合成的计算公式就会像下面这样：

```
								
                       0.5   0               0.5
R = S + D * (1 - Sa) = 0   + 0 * (1 - 0.5) = 0
                       0     1               0.5
```

我们最终会得到的RGB值为（0.5， 0， 0.5），它可能是饱和的李子的颜色或者紫色。当在蓝色背景上混合半透明的红色时这就是我们直觉所期待看到的。

记住我们只是将一个纹理的像素与另一个纹理的像素进行了合成。GPU需要在两个纹理重合的时候对所有的像素执行合成的操作。就像你所知道的，大部分的app都有很多的层级，因此这些纹理需要被一起合成。这将会使GPU非常的忙碌，即使这是能够非常高效执行这些事情的硬件。

### 不透明 vs 透明

当源纹理绝对不透明的时候，结果的纹理就是源纹理。这可以节省很多GPU的工作量，它可以简单的从源纹理复制，而不是合成所有的像素。但是GPU是没有办法知道纹理中的像素是透明的还是不是透明的。只有程序员能知道你在视图层上到底放了什么。这也是为什么CALayer有个属性叫做opaque。如果这个值为YES，那么GPU就不会做任何合成的操作，只是简单的从视图进行复制，而不用去管这个事图下面还有什么。这为GPU节省了非常多的工作。这也是Instrument工具中color blended layers选项所涉及的。它可以允许你看到那个图层（纹理）被标记为不透明的，那些图层让GPU做了合成的操作。合成不透明的图层是非常廉价的，因为涉及到了更少的数学操作。

如果你知道你的图层是不透明的，那就设置opaque属性为YES。如果你加载一张没有alpha通道的图片，并且在UIImageView中展示，那么这将自动发生。但是需要注意的是，一张图片没有alpha通道，跟有100%alpha值是完全不一样的。对于后一种情况，Core Animation会假设这张图片可能alpha值不是100%。在Finder中，你可以使用Get Info去获取到更多信息。它会告诉你，这张图片有没有alpha通道。

### 像素对齐与不对齐

到目前为止，我们看到的图层的像素在展示的时候都是完美对齐的。当所有的东西都是像素对齐的时候，我们可以获得相对简单的数学运算。每当GPU需要计算出屏幕上的像素颜色的时候，它只需要关注这个屏幕上方的图层的像素，并将他们组合到一起。或者，如果最上层的纹理是不透明的，那么GPU只需要简单的从这个纹理进行像素的拷贝。

当一个图层上的像素与屏幕上的像素完美对齐的时候，那么我们就说这个图层是像素对齐的。这里有两个主要的原因会造成像素的不对齐。第一个原因就是缩放，当一个纹理被放大或者缩小的时候，纹理的像素就将不会跟屏幕对齐。第二个原因就是纹理的起点不跟像素边界对齐。（比如origin = {10.2, 50.3 }）

在这两种情况下，GPU都需要做额外的数学运算。它会将多个像素与源像素进行混合生成的新值进行合成。当所有的图层都是像素对齐的时候，GPU就只需要做很少的工作。

再一次的，Core Animation Instrument有一个叫做color misaligned images的选项，会告诉我们什么时候会在图层上发生像素不对齐的情况。

### 蒙板

一个图层可以有一个与之关联的蒙版。蒙板是一个拥有透明度的位图，在图层与下面的内容进行合成之前，蒙板会应用到这个图层上去。当你要设置一个圆角，你可以有效的在图层上设置一个蒙板。当然，它也可以指定任意的蒙板，比如字母A。只有在蒙板中的图层才会被渲染出来。